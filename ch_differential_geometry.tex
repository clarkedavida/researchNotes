\chapter{Math: Differential Geometry}
\section{Topological manifolds}
Why should a physicist care about topology? Frederic Schuller gave a good
motivation for learning topology in the 2015 Winter School on Gravity and
Light~\cite{schuller}: we need to be able to speak sensibly about 
continuity in the most general way possible. In particular, we need 
to understand what it means for maps between manifolds to be continuous.  
Let $M$ be a set. A {\it topology on $M$}\index{topology} is a subset
$\topol{M}\subset2^M$ satisfying
\begin{enumerate}
  \item $\emptyset,M\in\topol{M}$;
  \item $U\in\topol{M}$ and $V\in\topol{M}$ $\Rightarrow
         U\cap V\in\topol{M}$; and
  \item $\{U_\alpha\}\in\topol{M}\Rightarrow
           \bigcup\limits_\alpha U_\alpha\in\topol{M}$.
\end{enumerate}
A {\it topological space}\index{topological!space} is a pair 
$(M,\topol{M})$. The sets $U$ are said to be {\it open}\index{set!open}, 
while a set $A$ is said to be {\it closed}\index{set!closed} if
and only if $M-A$ is open.

\begin{example*}{}{}
  \leavevmode
  \begin{enumerate}
    \item For any set $M$, the {\it chaotic topology}\index{topology!chaotic} 
          is given by $\topol{\text{chaotic}}=\{\emptyset,M\}$. On the 
          opposite end of the spectrum, the {\it discrete topology}
          \index{topology!discrete} is simply $\topol{\text{discrete}}=2^M$.
    \item Consider $\R^n$ equipped with the Euclidean metric. The
          {\it standard topology} \index{topology!standard} is 
          $$\topol{\text{standard}}=
          \{U\in2^{\R^n}:\Forall p\in U,\ \Exists r>0\ 
          \text{with}\ B_r(p)\in U\}.$$ Note in this case that the topological
          definition of open set agrees with the definition that relies
          on limit points.
  \end{enumerate}
\end{example*}
Let $(M,\topol{M})$ and $(N,\topol{N})$ be topological spaces. A mapping
$f:M\to N$ is {\it continuous}\index{map!continuous} if 
$\Forall V\in \topol{N}$, $f^{-1}(V)\in\topol{M}$.
In other words, continuous functions are those that guarantee that you started
off in an open set, if you ended up in an open set. Note that whether a
function is continuous depends on the topology.
\begin{theorem}{}{}
  Let $M$, $N$, and $P$ be open sets with respective topologies and suppose
  $f:M\to N$ and $g:N\to P$ are continuous. Then $g\circ f:M\to P$ is
  continuous.
  \begin{proof}
    We need to check that the preimage of $g\circ f$ is open. Note
    \begin{equation*}
    \begin{aligned}
      (g\circ f)^{-1}(P)&=\{m\in M:g\circ f(m)\in P\}\\
        &=\{m\in M:f(m)\in g^{-1}(P)\}\\
        &=f^{-1}(g^{-1}(P)).
    \end{aligned}
    \end{equation*}
    Since $g$ is continuous, $g^{-1}(P)$ is open. It follows by
    the continuity of $f$ that $f^{-1}(g^{-1}(P))$ is open,
    which completes the proof.
  \end{proof}
\end{theorem}
Hence the composition of continuous functions is continuous, which is what
you learned in calculus. Using the definition of continuity, we can know
determine when two topological spaces are, in some sense, equivalent.
A map between two topological spaces $f:M\to N$ is called a 
{\it homeomorphism}\index{map!homeomorphic} if
\begin{enumerate}
  \item $f$ is invertible;
  \item $f$ is continuous with respect to the topologies of $M$ and $N$; and
  \item $f^{-1}$ is also continuous.
\end{enumerate}
If such a function exists, we say $M$ and $N$ are {\it homeomorphic}.
So for example when a topological space is homeomorphic to
$\R^d$, that topological space is essentially a warped version
of $\R^d$. Also given a topological space, we can always make another
one from a subset of that space. In fact
\begin{proposition}{}{}
  Let $(M,\topol{M})$ be a topological space. Let $S\subseteq M$ and
  $\topol{M}|_S\subseteq 2^S$ such that 
  $\topol{M}|_S=\{U\cap S:U\in\topol{M}\}$. Then $(S,\topol{M}|_S)$ forms
  a topological space.
\end{proposition}
Let $d\in\N$. A topological space $(M,\topol{M})$ is called a
{\it topological manifold of dimension d}\index{manifold} if $\Forall x\in M$, 
$\Exists U$ containing $x$ that is homeomorphic to $\R^d$. Here
$\R^d$ is taken with the standard topology. We say:
\begin{enumerate}\index{chart}\index{atlas}\index{map!chart}
  \item $(U,f)$ is a {\it chart} of $(M,\topol{M})$.
  \item An {\it atlas} $\mathcal{A}$ is a collection of charts
        $(U_\alpha,f_\alpha)$ such that $M=\bigcup_\alpha U_\alpha$.
  \item Sometimes we call the homeomorphism for each chart a
        {\it chart map}.
\end{enumerate}
Clearly mathematicians got carried away with sailing analogies. But I think
they make the meaning of the terminology easy to remember. Now let's say that
I have two charts $(U_x,f)$ and $(U_y,g)$ of points $x$ and $y$ in the
manifold, and suppose further they overlap, i.e. $U_x\cap U_y\neq\emptyset$.
Consider a point $z$ in the intersection. Each chart gives me a perfectly
reasonable representation of $z$. How can I easily translate from one to the
other? Well, since $f$ and $g$ are invertible by definition the map
$$g\circ f^{-1}:f(U_x\cap U_y)\to g(U_x\cap U_y)$$
will do the trick.\index{map!chart transition}
$g\circ f^{-1}$ is called the {\it chart transition map}.
Informally, the chart transition map tells you how the charts of an atlas meld
together to form the manifold. It's also useful in the following sense: We
want to be able to do things, such as judging whether a path is continuous, by
only looking at charts. If we look at a chart and find that it is continuous,
can we guarantee that the path is as well? Because of the chart transition
map, we can. Let's call the path $\gamma$ and let $f$ and $g$ be two chart
maps. Now suppose we find that $f\circ\gamma$ is continuous. Then it follows
that $g\circ\gamma=g\circ f^{-1}\circ f\circ\gamma$ is continuous. Hence we 
know that we can define continuity of $\gamma$ in this way, that this is a
well-defined notion, because this notion does not depend on our choice of
chart map.

\section{Multilinear algebra}
Let $V$ and $W$ be vector spaces.
The set of linear maps from $V$ to $W$ is denoted by Hom($V$,$W$).
\begin{proposition}{}{}
  \normalfont{Hom($V$,$W$)} forms a vector space under vector addition 
  and scalar multiplication operations of $W$. 
\end{proposition}
We will now learn about a very special vector space. Given $V$ along with
this new vector space, we will be able to construct many other vector spaces.
The {\it dual space}\index{dual space} 
is given by $V^*\equiv\text{Hom}(V,\R)$.
An element of the dual space is called a {\it one-form} or {\it covector}.
\index{one-form}\index{covector}
Let $V$ be $n$-dimensional with basis $\{e^1,...,e^n\}$. If a basis
$\{\epsilon_1,...,\epsilon_n\}$ of $V^*$ satisfies
  $$\epsilon^a(e_b)=\delta^a_b$$
\index{dual basis}
then it is called the {\it dual basis} of $V^*$.
\begin{theorem}{}{}
  If \normalfont{dim}(V)$\;<\infty$, then $\big(V^*\big)^*=V$.
\end{theorem}
\begin{example*}{}{}
  Consider the 4D vector space of polynomials of degree 3 with
  real coefficients. A basis for this space is $\{1,x,x^2,x^3\}$. 
  The dual space is the set of mixed differential operators of order 3 or 
  smaller. It's not hard to see that the dual basis is 
  $$\Bigg\{1,\pdv{x},
             \frac{1}{2}\frac{\partial^2}{\partial x^2},
             \frac{1}{6}\frac{\partial^3}{\partial x^3}\Bigg\}.$$
\end{example*}
Perhaps you encountered tensors in physics and were told something useless
like ``a tensor is an object that transforms like a tensor."
You will now get to see a more illuminating definition.
  Let $r,s\in\N$.\index{tensor}
  A {\it tensor of rank ($r$,$s$)} is a map
  $$T:\underbrace{V^*\times...\times V^*}_\text{$r$ times}\times
      \underbrace{V\times...\times V}_\text{$s$ times}\to\R$$
  that is linear in all its arguments.
In other words, a tensor is a multilinear map that eats
vectors and covectors and spits out a real number. Now, you may be used
to (1,1) tensors being objects that take vectors to vectors. Given
a tensor $T$, we can actually recover such a construction.
\begin{example*}{}{}
  Given a tensor $T:V^*\times V\to\R$, where $V$ is a vector space
  of finite dimension, define the map $\phi:V\to \big(V^*\big)^*=V$ by
  $$\phi(v)=T(\cdot,v),$$
  where $v\in V$ and the $\cdot$ represents an as-yet-unspecified covector. 
  We see that the RHS of the above equation is an element of $(V^*)^*$ 
  since it eats covectors and spits out real numbers. So the map $\phi$ takes
  a vector to a vector. Similarly if we 
  define the map $\phi:V^*\to V^*$ by
  $$\phi(\omega)=T(\omega,\cdot),$$
  where $\omega\in V^*$ and $\cdot$ is an as-yet-unspecified vector, we see
  $\phi$ takes a covector to a covector.
\end{example*}
\begin{example*}{}{}
 Here are some more familiar tensors:
  \begin{enumerate}
    \item Clearly rank (0,1) tensors are covectors, which is why they are 
          also called one-forms. Similarly rank (1,0) tensors are vectors.
    \item An inner product is a rank (0,2) tensor.
    \item The gradient is a rank (0,1) tensor.
  \end{enumerate}
\end{example*}
Again let $V$ be finite dimensional. Given a basis of $V$ and the corresponding
dual basis of $V^*$, we can write $\Forall v\in V$ and $\Forall \omega\in V^*$
\begin{equation}
  v=v^1e_1+...+v^ne_n,~~~\omega=\omega_1\epsilon^1+...+\omega_n\epsilon^n.
\end{equation}
That is, we can write $v$ in terms of its components $v^i$ and $\omega$ in
terms of its components $\omega_i$. We can do the same thing for tensors.
For a rank $(r,s)$ tensor, each component is given by
\begin{equation}
  T\indices{^{i_1...i_r}_{j_1...j_s}}
    =T(\omega^{i_1},...,\omega^{i_r},e_{j_1},...,e_{j_s}),
\end{equation}
where $1\leq i,j\leq n$.

\bibliographystyle{unsrtnat}
\bibliography{bibliography}

